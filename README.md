# Aura ‚Äì AI Life Coach (Continuous Speech + Emotional Intelligence)

> Real-time, privacy-conscious AI life coach that listens continuously, tracks emotional trends, and surfaces deep behavioral patterns.

<p align="center">
   <img src="screenshot.png" alt="Aura main emotional state and graph screenshot" width="420" />
</p>

## üöÄ Overview

Aura is a SwiftUI iOS application that acts as an always-on reflective companion. It continuously transcribes speech locally, periodically summarizes and analyzes what you say, extracts emotions every 30 seconds, and (on demand) performs a **Daily Pattern Analysis** to uncover repeating themes, emotional spikes, coping loops, and growth signals.

The experience is split into focused tabs:

- **My Aura** ‚Äì Clean end‚Äëuser view: current emotional state + trend graph + primary listening control.
- **Chat** ‚Äì Reflective therapy-style chat using recent transcript, emotional trend, and detected patterns for context (concise 2‚Äì4 sentence coaching turns).
- **Daily** ‚Äì One‚Äëoff full‚Äëday behavioral / emotional pattern mining with structured JSON parsing.
- **Debug** ‚Äì Rich diagnostics: raw transcript flow, timers, manual triggers, internal states.
- **Settings** ‚Äì Enable multiple speech recognition languages (English / Deutsch / –†—É—Å—Å–∫–∏–π), pick a Primary, optional auto‚Äëdetect that switches when confidence is high.

## ‚ú® Core Features

| Category                     | Capability                                                             |
| ---------------------------- | ---------------------------------------------------------------------- |
| Continuous Listening         | Auto starts after permission; segments speech by silence & timing      |
| Adaptive Accumulation        | Bundles ~1 minute of meaningful speech before AI insight request       |
| AI Coaching Responses        | Structured conversation context ‚Üí Theta EdgeCloud (Llama / similar)    |
| Emotional Snapshots          | Automatic + manual emotional analysis every 30s (Neutral fallback)     |
| Emotional Trend Graph        | Strava‚Äëlike area graph + emoji row & positivity baseline               |
| Daily Pattern Analysis       | One‚Äëoff transcript mining ‚Üí patterns (title, summary, emoji, evidence) |
| Resilient Parsing            | Multi‚Äëstrategy emotion + JSON extraction w/ heuristic fallback         |
| Rate Limiting & Context Mgmt | Cooldown & trimmed rolling buffer (max messages)                       |
| Privacy‚ÄëAware                | In-memory transcript only (no persistence yet)                         |
| Debug Utilities              | Test prompt, timers, diagnostics logging                               |
| Auto Language Detection      | NL language recognizer w/ confidence + cooldown switching              |

Legacy feature notes retained: earlier Whisper transcription approach evolved into a custom continuous speech pipeline; CBT‚Äëstyle coaching retained in prompt persona.

## üß† Product Philosophy

Reduce friction in self‚Äëreflection:

- Passive capture ‚Üí active insight
- Lightweight emotional bio‚Äëfeedback
- Pattern surfacing for habit change
- Coaching tone: supportive, contextual, concise

## üèó Architecture

**Pattern:** MVVM + service layer.

```
AuraApp
   ‚îî‚îÄ‚îÄ ContentView (TabView)
            ‚îú‚îÄ‚îÄ CleanAuraView      (consumer UI)
            ‚îú‚îÄ‚îÄ DailyAnalysisView  (full-day pattern mining)
            ‚îî‚îÄ‚îÄ DebugView          (diagnostics + controls)

ChatViewModel (@MainActor)
   ‚îú‚îÄ‚îÄ ContinuousSpeechService  (streaming SFSpeechRecognizer orchestration)
   ‚îú‚îÄ‚îÄ ThetaAPIService          (conversation + one-off inference requests)
   ‚îú‚îÄ‚îÄ EmotionalAnalysisService (30s emotion snapshots)
   ‚îú‚îÄ‚îÄ ThetaEdgeAnalysisService (experimental periodic thematic analyzer)
   ‚îî‚îÄ‚îÄ State: messages, accumulatedText, livePartial, emotionalTrend, dailyPatterns
```

### Key State Flows

1. **Speech ‚Üí Accumulation:** `ContinuousSpeechService` builds `accumulatedText` while tracking silence, noise floor, confidence & session boundaries.
2. **Accumulation ‚Üí AI Insight:** After interval / condition, `ChatViewModel` posts accumulated block via `ThetaAPIService.generateAIInsight()`; AI reply appended to chat.
3. **Emotional Polling:** 30s timer (plus manual trigger) calls `EmotionalAnalysisService.analyzeText()` on merged snapshot (accumulated + live partial). Result normalized ‚Üí appended to `emotionalTrend`.
4. **Daily Pattern Mining:** User taps ‚ÄúAnalyse my patterns‚Äù ‚Üí `oneOffAnalysis()` with JSON-only prompt over truncated transcript (last 12k chars). Parsed ‚Üí `[DailyPattern]`.

### Resilience & Safeguards

- Default Neutral emotion so UI never blank.
- Conversational requests rate-limited; daily analysis bypasses but updates timestamp.
- JSON parsing fallback if LLM returns prose.
- Context trimming & transcript truncation to prevent oversized payloads.

## üîç Notable Implementation Details

- **Swift Concurrency:** Async/await for network + emotion tasks; main actor state mutations.
- **Combine:** Service publishers (audio level, partial transcript) bridged into SwiftUI.
- **Graph Rendering:** Custom path + gradient + emoji row outside clipped chart.
- **Parsing Strategies:** Colon split, emoji scan, whitelist keywords for emotions; JSON substring or bullet heuristic for patterns.
- **Prompts:** Persona system prompt for coaching; dedicated minimal JSON extraction prompt for pattern analysis.
 - **Auto Language Detection:** Aggregates recent final utterances (‚â§6, ‚â•25 chars total) ‚Üí `NLLanguageRecognizer`; switches primary language if mapped locale in enabled set (or auto-add), confidence ‚â•0.65, and ‚â•90s since prior switch.

## ÔøΩ Key Source Files

| File                             | Purpose                                  |
| -------------------------------- | ---------------------------------------- |
| `AuraApp.swift`                  | App entry & env loading                  |
| `ContentView.swift`              | Tab orchestration & major subviews       |
| `ChatViewModel.swift`            | Core orchestration & published state     |
| `ContinuousSpeechService.swift`  | Continuous speech recognition pipeline   |
| `ThetaAPIService.swift`          | Conversation + one-off analysis requests |
| `EmotionalAnalysisService.swift` | Emotional snapshot analyzer              |
| `ThetaEdgeAnalysisService.swift` | Experimental thematic analyzer           |
| `AudioService.swift`             | Legacy / alternative speech approach     |
| `ChatMessage.swift`              | Chat message model                       |
| `Config.swift`                   | Environment variable loader              |

## ‚öôÔ∏è Configuration

Create a `.env` file (loaded at launch) with:

```
THETA_API_KEY=your_theta_edge_api_key_here
```

Ensure the key has access to the endpoints configured in `ThetaAPIService.baseURL`.

## ‚ñ∂Ô∏è Running the App

1. Open `Aura.xcodeproj` in Xcode 15+.
2. Add your `.env` file (not committed).
3. Build & run on a physical device for best speech input.
4. Grant microphone & speech recognition permissions.
5. Speak naturally; observe emotional graph; run Daily analysis when ready.

## üí¨ Usage Flow

1. Launch ‚Üí permissions auto-check ‚Üí continuous listening starts.
2. Speak freely; transcript accrues.
3. Aura periodically responds & updates emotion every 30s.
4. Open **Daily** tab for end-of-session pattern mining.

## üìä Emotional Trend Scoring

Internal mapping (`score(for:)`) converts emotions ‚Üí [-1, +1] for vertical placement.

## üß© Daily Pattern Output (Example)

```json
{
  "patterns": [
    {
      "title": "Evening Rumination",
      "summary": "You revisit unresolved work thoughts after 9pm, raising anxiety.",
      "emoji": "üåÄ",
      "evidence": "kept thinking about the project after dinner"
    }
  ]
}
```

Heuristic fallback: bullet-like lines if JSON parse fails.

## üîê Privacy

- Transcript in-memory only (session scope).
- No audio persistence. Only text context sent upstream.
- Future: optional local summarization + persistence encryption.

## ÔøΩ Roadmap

| Area                 | Idea                                                                     |
| -------------------- | ------------------------------------------------------------------------ |
| Persistence          | Secure storage of emotional trend & patterns                             |
| Personalization      | Adaptive emotion taxonomy, user mood tagging                             |
| UI                   | Tap-to-inspect graph points / pattern drill-down                         |
| Coaching Loop        | Action items & reminders                                                 |
| Privacy              | Edge summarization before cloud send                                     |
| Analytics            | Sentiment volatility, streak metrics                                     |
| Offline              | Local fallback model (basic emotion)                                     |
| Internationalization | Multi-language speech support (prototype language switching implemented) |

## üß™ Testing Suggestions

- Mock `ThetaAPIService` to inject deterministic responses.
- Unit test emotion parsing permutations (colon / emoji / whitelist).
- Snapshot test `EmotionalTrendGraph` with synthetic data.

## ‚ö†Ô∏è Known Limitations

- No persistence (loss on restart).
- Transcript truncated for daily analysis (12k char suffix).
- Pattern extraction depends on LLM JSON compliance.
- Overlap between `AudioService` & `ContinuousSpeechService` (one could be retired).

## ü§ù Contributing

1. Fork & branch (`feature/my-improvement`).
2. Implement focused change (small PRs preferred).
3. Add minimal test or reproduction notes.
4. Submit PR with before/after behavior summary.

## üìÑ License

Proprietary (add chosen license or convert to OSS later).

---

**Aura** turns passive speech into actionable emotional + behavioral insight. Speak. Observe. Adapt.
